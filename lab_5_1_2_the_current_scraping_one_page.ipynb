{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - The Current - Part 2\n",
    "\n",
    "* The Current is an alternative radio station\n",
    "* We will pull information about the play list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0 - Insert current progress\n",
    "\n",
    "Copy over all the relevant code from part 1 of the lab.\n",
    "\n",
    "http://www.thecurrent.org/playlist/2014-01-01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: composable in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.5)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Requirement already satisfied: composablesoup in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied: composable<0.3.0,>=0.2.0 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.5)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.3 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already up-to-date: composable in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (18.6.0)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable) (0.11.1)\n",
      "Requirement already up-to-date: composablesoup in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (0.2.4)\n",
      "Requirement already satisfied, skipping upgrade: python-forge<19.0,>=18.6 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (18.6.0)\n",
      "Requirement already satisfied, skipping upgrade: beautifulsoup4<5.0.0,>=4.9.3 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (4.9.3)\n",
      "Requirement already satisfied, skipping upgrade: composable<0.3.0,>=0.2.0 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composablesoup) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: soupsieve>1.2; python_version >= \"3.0\" in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.9.3->composablesoup) (1.9.5)\n",
      "Requirement already satisfied, skipping upgrade: toolz<0.12.0,>=0.11.1 in /home/ki6241pu/.pyenv/versions/anaconda3-2020.02/lib/python3.7/site-packages (from composable<0.3.0,>=0.2.0->composablesoup) (0.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install composable\n",
    "!pip install composablesoup\n",
    "!pip install composable --upgrade\n",
    "!pip install composablesoup --upgrade\n",
    "from composablesoup import find, find_all, get_text, has_attr\n",
    "from composable.sequence import slice, head\n",
    "from composable.strict import map, filter\n",
    "from composable.string import replace, split\n",
    "from composable import from_toolz as tlz\n",
    "from composable import pipeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "s = requests.Session()\n",
    "r = s.get('https://www.thecurrent.org/playlist/2014-01-01/01')\n",
    "the_current = BeautifulSoup(r.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull off the song start time\n",
    "\n",
    "1. Inspect the element\n",
    "    1. This one is tricky\n",
    "    2. Time tag does not have a tag, but\n",
    "    3. The surrounding div does have a class\n",
    "2. Identify the html tag and class\n",
    "3. Use `find_all` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Write a function that extracts the start time.\n",
    "6. Write a single pipe to extract the start time.\n",
    "7. Confirm you have the right number of times.\n",
    "8. Package your code in a function called `get_start_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"two columns songTime\">\n",
       " <a href=\"#song226645\">\n",
       " <time>  1:59 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song196069\">\n",
       " <time>  1:54 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song229900\">\n",
       " <time>  1:51 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song235779\">\n",
       " <time>  1:46 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song132616\">\n",
       " <time>  1:44 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song224268\">\n",
       " <time>  1:38 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song236492\">\n",
       " <time>  1:34 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song237794\">\n",
       " <time>  1:31 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song234211\">\n",
       " <time>  1:27 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song235959\">\n",
       " <time>  1:23 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song232235\">\n",
       " <time>  1:19 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song190810\">\n",
       " <time>  1:13 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song236192\">\n",
       " <time>  1:09 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song229658\">\n",
       " <time>  1:05 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song221276\">\n",
       " <time>  1:03 </time>\n",
       " </a>\n",
       " </div>,\n",
       " <div class=\"two columns songTime\">\n",
       " <a href=\"#song131853\">\n",
       " <time>  1:01 </time>\n",
       " </a>\n",
       " </div>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(the_current\n",
    " >> find_all('div', attrs = {'class':'songTime'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n  1:59 \\n\\n',\n",
       " '\\n\\n  1:54 \\n\\n',\n",
       " '\\n\\n  1:51 \\n\\n',\n",
       " '\\n\\n  1:46 \\n\\n',\n",
       " '\\n\\n  1:44 \\n\\n',\n",
       " '\\n\\n  1:38 \\n\\n',\n",
       " '\\n\\n  1:34 \\n\\n',\n",
       " '\\n\\n  1:31 \\n\\n',\n",
       " '\\n\\n  1:27 \\n\\n',\n",
       " '\\n\\n  1:23 \\n\\n',\n",
       " '\\n\\n  1:19 \\n\\n',\n",
       " '\\n\\n  1:13 \\n\\n',\n",
       " '\\n\\n  1:09 \\n\\n',\n",
       " '\\n\\n  1:05 \\n\\n',\n",
       " '\\n\\n  1:03 \\n\\n',\n",
       " '\\n\\n  1:01 \\n\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(the_current\n",
    " >> find_all('div', attrs = {'class':'songTime'})\n",
    " >> map(get_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "strip = pipeable(lambda s: s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:59',\n",
       " '1:54',\n",
       " '1:51',\n",
       " '1:46',\n",
       " '1:44',\n",
       " '1:38',\n",
       " '1:34',\n",
       " '1:31',\n",
       " '1:27',\n",
       " '1:23',\n",
       " '1:19',\n",
       " '1:13',\n",
       " '1:09',\n",
       " '1:05',\n",
       " '1:03',\n",
       " '1:01']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_start_time = pipeable( lambda soup: soup\n",
    "                         >> find_all('div', attrs = {'class':'two columns songTime'})\n",
    "                         >> map(get_text)\n",
    "                         >> map(strip)\n",
    "                        )\n",
    "the_current >> get_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull address of the album art image address\n",
    "\n",
    "Follow a similar process to pull off the web address of the album cover image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"We The Common\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/e2/e2749c25-c2b6-493e-a2bb-10898152bd2d_5158.jpg\" src=\"\" title=\"Thao and The Get Down Stay Down - We The Common\"/>,\n",
       " <img alt=\"default album cover image\" class=\"album-art\" src=\"/assets/album-cover-default-32217dc68a771f3a44aa2b7a640cf91133b61bd1f2ae68c9ddb00055e9a8ac1d.png\"/>,\n",
       " <img alt=\"default album cover image\" class=\"album-art\" src=\"/assets/album-cover-default-32217dc68a771f3a44aa2b7a640cf91133b61bd1f2ae68c9ddb00055e9a8ac1d.png\"/>,\n",
       " <img alt=\"Wildewoman\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/5e/5e5c8b95-d04c-432f-8cd2-c1c8d99e6e5a_3556.jpg\" src=\"\" title=\"Lucius - Wildewoman\"/>,\n",
       " <img alt=\"Frosting on the Beater\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/48/48445b64-d965-369a-af3c-8193de389fd8_3ff4.jpg\" src=\"\" title=\"The Posies - Frosting on the Beater\"/>,\n",
       " <img alt=\"default album cover image\" class=\"album-art\" src=\"/assets/album-cover-default-32217dc68a771f3a44aa2b7a640cf91133b61bd1f2ae68c9ddb00055e9a8ac1d.png\"/>,\n",
       " <img alt=\"default album cover image\" class=\"album-art\" src=\"/assets/album-cover-default-32217dc68a771f3a44aa2b7a640cf91133b61bd1f2ae68c9ddb00055e9a8ac1d.png\"/>,\n",
       " <img alt=\"Foreverly\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/e9/e999c049-c65b-4c5e-ad12-5596998679c7_92f9.jpg\" src=\"\" title=\"Billie Joe and Norah - Foreverly\"/>,\n",
       " <img alt=\"Essential Tremors\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/d6/d62320e2-20c4-4589-aa76-2f8ac28447dd_e03b.jpg\" src=\"\" title=\"J. Roddy Walston and The Business - Essential Tremors\"/>,\n",
       " <img alt=\"Static\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/02/028b8602-3bde-495a-a7da-15594fc4f786_351a.jpg\" src=\"\" title=\"Cults - Static\"/>,\n",
       " <img alt=\"...Like Clockwork\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/c9/c92f73ee-527f-42ed-a556-fd615941e214_78f0.jpg\" src=\"\" title=\"Queens of the Stone Age - ...Like Clockwork\"/>,\n",
       " <img alt=\"default album cover image\" class=\"album-art\" src=\"/assets/album-cover-default-32217dc68a771f3a44aa2b7a640cf91133b61bd1f2ae68c9ddb00055e9a8ac1d.png\"/>,\n",
       " <img alt=\"Magpie and the Dandelion\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/24/24084807-5d23-423e-b1f3-5e9fd874e240_6ccd.jpg\" src=\"\" title=\"The Avett Brothers - Magpie and the Dandelion\"/>,\n",
       " <img alt=\"The Next Day\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/c2/c20be759-d767-4a7c-96c5-7a870ebc3a30_7f7d.jpg\" src=\"\" title=\"David Bowie - The Next Day\"/>,\n",
       " <img alt=\"Blunderbuss\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/37/37f48931-e5e6-488f-a531-ad2db311158d_7446.jpg\" src=\"\" title=\"Jack White - Blunderbuss\"/>,\n",
       " <img alt=\"Doolittle\" class=\"album-art lazyload\" data-src=\"https://albumart.publicradio.org/mb/1a/1aa41b19-5a72-341b-bd91-4cf61d1dab6b_8e05.jpg\" src=\"\" title=\"Pixies - Doolittle\"/>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(the_current\n",
    " >> find_all('img', attrs = {'class':'album-art'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pipeable(lambda L: [tlz.get('data-src') for i in L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "give_default = pipeable(lambda l: [\"/assets/album-cover-default-32217dc....png\" for i in l if i == \"\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://albumart.publicradio.org/mb/e2/e2749c25-c2b6-493e-a2bb-10898152bd2d_5158.jpg',\n",
       " 'https://albumart.publicradio.org/mb/5e/5e5c8b95-d04c-432f-8cd2-c1c8d99e6e5a_3556.jpg',\n",
       " 'https://albumart.publicradio.org/mb/48/48445b64-d965-369a-af3c-8193de389fd8_3ff4.jpg',\n",
       " 'https://albumart.publicradio.org/mb/e9/e999c049-c65b-4c5e-ad12-5596998679c7_92f9.jpg',\n",
       " 'https://albumart.publicradio.org/mb/d6/d62320e2-20c4-4589-aa76-2f8ac28447dd_e03b.jpg',\n",
       " 'https://albumart.publicradio.org/mb/02/028b8602-3bde-495a-a7da-15594fc4f786_351a.jpg',\n",
       " 'https://albumart.publicradio.org/mb/c9/c92f73ee-527f-42ed-a556-fd615941e214_78f0.jpg',\n",
       " 'https://albumart.publicradio.org/mb/24/24084807-5d23-423e-b1f3-5e9fd874e240_6ccd.jpg',\n",
       " 'https://albumart.publicradio.org/mb/c2/c20be759-d767-4a7c-96c5-7a870ebc3a30_7f7d.jpg',\n",
       " 'https://albumart.publicradio.org/mb/37/37f48931-e5e6-488f-a531-ad2db311158d_7446.jpg',\n",
       " 'https://albumart.publicradio.org/mb/1a/1aa41b19-5a72-341b-bd91-4cf61d1dab6b_8e05.jpg']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_img_address = pipeable( lambda soup: soup\n",
    "                          >> find_all('img', attrs = {'class':'album-art'})\n",
    "                          >> filter(has_attr('data-src'))\n",
    "                          #>> give_default\n",
    "                          >> map(tlz.get('data-src'))\n",
    "                           #>> test\n",
    "                          )\n",
    "the_current >> get_img_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on pipeable in module toolz.itertoolz:\n",
      "\n",
      "get(ind='__no__default__', seq='__no__default__', default='__no__default__')\n",
      "    Get element in a sequence or dict\n",
      "    \n",
      "    Provides standard indexing\n",
      "    \n",
      "    >>> get(1, 'ABC')       # Same as 'ABC'[1]\n",
      "    'B'\n",
      "    \n",
      "    Pass a list to get multiple values\n",
      "    \n",
      "    >>> get([1, 2], 'ABC')  # ('ABC'[1], 'ABC'[2])\n",
      "    ('B', 'C')\n",
      "    \n",
      "    Works on any value that supports indexing/getitem\n",
      "    For example here we see that it works with dictionaries\n",
      "    \n",
      "    >>> phonebook = {'Alice':  '555-1234',\n",
      "    ...              'Bob':    '555-5678',\n",
      "    ...              'Charlie':'555-9999'}\n",
      "    >>> get('Alice', phonebook)\n",
      "    '555-1234'\n",
      "    \n",
      "    >>> get(['Alice', 'Bob'], phonebook)\n",
      "    ('555-1234', '555-5678')\n",
      "    \n",
      "    Provide a default for missing values\n",
      "    \n",
      "    >>> get(['Alice', 'Dennis'], phonebook, None)\n",
      "    ('555-1234', None)\n",
      "    \n",
      "    See Also:\n",
      "        pluck\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tlz.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "* Make a function for each of the previous steps\n",
    "* Make an overall function\n",
    "    * input is a soup\n",
    "    * output is a list of lists\n",
    "\n",
    "**Hint:** You should use `zip` to put all the information together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_period = pipeable( lambda soup: soup\n",
    "                         >> find('span', attrs = {'class':'hour-header'})\n",
    "                         >> get_text\n",
    "                         >> strip\n",
    "                         >> split(' ')\n",
    "                         >> tlz.get(1)\n",
    "                         )\n",
    "get_dj = pipeable(lambda soup: soup\n",
    "                    >> find('h5', attrs = {'class':'currentDj'})\n",
    "                    >> get_text\n",
    "                    >> split(': ')\n",
    "                    >> tlz.get(1)\n",
    "                 )\n",
    "get_weekday = pipeable(lambda soup: soup\n",
    "                    >> find('a', attrs = {'class':'start-picker'})\n",
    "                    >> get_text\n",
    "                    >> split(',')\n",
    "                    >> tlz.get(0)\n",
    "                 )\n",
    "get_title = pipeable(lambda soup: soup\n",
    "                     >> find_all('h5', attrs = {'class':'title'})\n",
    "                     >> map(get_text)\n",
    "                 )\n",
    "get_artist = pipeable(lambda soup: soup\n",
    "                     >> find_all('h5', attrs = {'class':'artist'})\n",
    "                     >> map(get_text)\n",
    "                 )\n",
    "get_start_time = pipeable( lambda soup: soup\n",
    "                         >> find_all('div', attrs = {'class':'two columns songTime'})\n",
    "                         >> map(get_text)\n",
    "                         >> map(strip)\n",
    "                        )\n",
    "get_img_address = pipeable( lambda soup: soup\n",
    "                          >> find_all('img', attrs = {'class':\"album-art\"})\n",
    "                          >> filter(has_attr('data-src'))\n",
    "                          >> map(tlz.get('data-src'))\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-538106c4c3fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0;34m>>\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0;34m>>\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m            \u001b[0;34m>>\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomma_join\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m           )\n\u001b[1;32m      8\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "from composable.strict import zipOnto\n",
    "#from composable.list import to_list\n",
    "combine = (the_current\n",
    "           >> zip(get_period, get_dj)\n",
    "           >> to_list\n",
    "           >> map(comma_join)\n",
    "          )\n",
    "combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-2ba1ff07b174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "combine = zip(get_period, get_dj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('am',\n",
       "  'Jade',\n",
       "  'Wednesday',\n",
       "  'Holy Roller',\n",
       "  'Thao and The Get Down Stay Down',\n",
       "  '1:59'),\n",
       " ('am', 'Jade', 'Wednesday', 'Kingdom of Rust', 'Doves', '1:54'),\n",
       " ('am', 'Jade', 'Wednesday', 'Black Dog', 'Frankie Lee', '1:51'),\n",
       " ('am', 'Jade', 'Wednesday', 'Turn It Around', 'Lucius', '1:46'),\n",
       " ('am', 'Jade', 'Wednesday', 'Flavor of the Month', 'The Posies', '1:44'),\n",
       " ('am', 'Jade', 'Wednesday', 'Potential Wife', 'Strange Names', '1:38'),\n",
       " ('am', 'Jade', 'Wednesday', '24 Hours', 'Sky Ferreira', '1:34'),\n",
       " ('am',\n",
       "  'Jade',\n",
       "  'Wednesday',\n",
       "  \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       "  'Billie Joe and Norah',\n",
       "  '1:31'),\n",
       " ('am',\n",
       "  'Jade',\n",
       "  'Wednesday',\n",
       "  'Marigold',\n",
       "  'J. Roddy Walston and The Business',\n",
       "  '1:27'),\n",
       " ('am', 'Jade', 'Wednesday', 'High Road', 'Cults', '1:23'),\n",
       " ('am',\n",
       "  'Jade',\n",
       "  'Wednesday',\n",
       "  'The Vampyre Of Time and Memory',\n",
       "  'Queens of the Stone Age',\n",
       "  '1:19'),\n",
       " ('am', 'Jade', 'Wednesday', 'Valerie Plame', 'The Decemberists', '1:13'),\n",
       " ('am', 'Jade', 'Wednesday', 'Morning Song', 'The Avett Brothers', '1:09'),\n",
       " ('am',\n",
       "  'Jade',\n",
       "  'Wednesday',\n",
       "  '(You Will) Set The World On Fire',\n",
       "  'David Bowie',\n",
       "  '1:05'),\n",
       " ('am', 'Jade', 'Wednesday', 'Sixteen Saltines', 'Jack White', '1:03'),\n",
       " ('am', 'Jade', 'Wednesday', 'Wave of Mutilation', 'Pixies', '1:01'))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info = lambda soup: zip(itertools.repeat(soup >> get_period), itertools.repeat(soup >> get_dj), itertools.repeat(soup >> get_weekday), soup >> get_title, soup >> get_artist, soup >> get_start_time)\n",
    "tuple(all_info(the_current))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
